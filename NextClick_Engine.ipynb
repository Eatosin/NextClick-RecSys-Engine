{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOk2MPhr3S1jZ38WTk3SAry",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Eatosin/NextClick-RecSys-Engine/blob/main/NextClick_Engine.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "tLJDPC29mLCp",
        "outputId": "b2f82804-8a79-4af1-e0b2-620ea6682011"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting wget\n",
            "  Downloading wget-3.2.zip (10 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (2.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (2.0.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas) (2025.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
            "Building wheels for collected packages: wget\n",
            "  Building wheel for wget (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for wget: filename=wget-3.2-py3-none-any.whl size=9655 sha256=38dafe19f373fc480aa6d9e94af650161cc4d9e697fd2e0d5c38e98492ba02bb\n",
            "  Stored in directory: /root/.cache/pip/wheels/01/46/3b/e29ffbe4ebe614ff224bad40fc6a5773a67a163251585a13a9\n",
            "Successfully built wget\n",
            "Installing collected packages: wget\n",
            "Successfully installed wget-3.2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:root:ðŸ“¡ Downloading MovieLens 1M dataset...\n",
            "INFO:root:\n",
            "âœ… Download Complete.\n",
            "INFO:root:ðŸ“¦ Extracting data...\n",
            "INFO:root:ðŸ§¹ Starting Preprocessing...\n",
            "INFO:root:ðŸ“Š Unique Movies: 3706\n",
            "INFO:root:ðŸ“Š Total Interactions: 1000209\n",
            "INFO:root:ðŸ”— Grouping by User Session...\n",
            "INFO:root:âœ… Data Processed. Users: 6040\n",
            "INFO:root:ðŸ’¾ Artifacts Saved to /content/data/processed/\n"
          ]
        }
      ],
      "source": [
        "# --- COLAB SETUP BLOCK ---\n",
        "!pip install wget pandas numpy\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import wget\n",
        "import zipfile\n",
        "import os\n",
        "import logging\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "DATA_URL = \"https://files.grouplens.org/datasets/movielens/ml-1m.zip\"\n",
        "RAW_DIR = \"/content/data/raw\"\n",
        "PROCESSED_DIR = \"/content/data/processed\"\n",
        "MIN_SESSION_LENGTH = 5\n",
        "\n",
        "# Configure Logging\n",
        "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
        "logger = logging.getLogger()\n",
        "logger.setLevel(logging.INFO)\n",
        "\n",
        "class DataPipeline:\n",
        "    def __init__(self):\n",
        "        os.makedirs(RAW_DIR, exist_ok=True)\n",
        "        os.makedirs(PROCESSED_DIR, exist_ok=True)\n",
        "\n",
        "    def download_data(self):\n",
        "        zip_path = os.path.join(RAW_DIR, \"ml-1m.zip\")\n",
        "        if not os.path.exists(zip_path):\n",
        "            logger.info(\"ðŸ“¡ Downloading MovieLens 1M dataset...\")\n",
        "            wget.download(DATA_URL, zip_path)\n",
        "            logger.info(\"\\nâœ… Download Complete.\")\n",
        "\n",
        "        logger.info(\"ðŸ“¦ Extracting data...\")\n",
        "        with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "            zip_ref.extractall(RAW_DIR)\n",
        "\n",
        "        return os.path.join(RAW_DIR, \"ml-1m/ratings.dat\")\n",
        "\n",
        "    def preprocess(self, file_path):\n",
        "        logger.info(\"ðŸ§¹ Starting Preprocessing...\")\n",
        "\n",
        "        # Load Data\n",
        "        df = pd.read_csv(file_path, sep='::', header=None, names=['uid', 'mid', 'rating', 'timestamp'], engine='python')\n",
        "\n",
        "        # Filter & Sort\n",
        "        df = df.sort_values(by=['uid', 'timestamp'])\n",
        "\n",
        "        # Mapping\n",
        "        unique_movies = df['mid'].unique()\n",
        "        movie_map = {mid: i + 1 for i, mid in enumerate(unique_movies)}\n",
        "        df['mid'] = df['mid'].map(movie_map)\n",
        "\n",
        "        logger.info(f\"ðŸ“Š Unique Movies: {len(unique_movies)}\")\n",
        "        logger.info(f\"ðŸ“Š Total Interactions: {len(df)}\")\n",
        "\n",
        "        # Grouping\n",
        "        logger.info(\"ðŸ”— Grouping by User Session...\")\n",
        "        user_group = df.groupby('uid')['mid'].apply(list)\n",
        "\n",
        "        # Filter\n",
        "        user_group = user_group[user_group.apply(len) >= MIN_SESSION_LENGTH]\n",
        "\n",
        "        # Splitting\n",
        "        train_seqs, val_seqs, test_seqs = [], [], []\n",
        "\n",
        "        for seq in user_group:\n",
        "            train_seqs.append(seq[:-2])\n",
        "            val_seqs.append(seq[:-1])\n",
        "            test_seqs.append(seq)\n",
        "\n",
        "        logger.info(f\"âœ… Data Processed. Users: {len(user_group)}\")\n",
        "\n",
        "        # Save\n",
        "        np.save(os.path.join(PROCESSED_DIR, \"train.npy\"), np.array(train_seqs, dtype=object))\n",
        "        np.save(os.path.join(PROCESSED_DIR, \"val.npy\"), np.array(val_seqs, dtype=object))\n",
        "        np.save(os.path.join(PROCESSED_DIR, \"test.npy\"), np.array(test_seqs, dtype=object))\n",
        "\n",
        "        # Save Metadata\n",
        "        with open(os.path.join(PROCESSED_DIR, \"meta.txt\"), \"w\") as f:\n",
        "            f.write(str(len(unique_movies) + 1))\n",
        "\n",
        "        logger.info(\"ðŸ’¾ Artifacts Saved to /content/data/processed/\")\n",
        "\n",
        "# Execution\n",
        "pipeline = DataPipeline()\n",
        "raw_path = pipeline.download_data()\n",
        "pipeline.preprocess(raw_path)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# --- MODEL CONFIGURATION ---\n",
        "MAX_LEN = 50       # Max sequence length to look back\n",
        "HIDDEN_UNITS = 64  # Embedding size\n",
        "NUM_HEADS = 2      # Attention heads (Multi-head attention)\n",
        "NUM_LAYERS = 2     # Transformer blocks\n",
        "DROPOUT = 0.2\n",
        "BATCH_SIZE = 128\n",
        "EPOCHS = 10        # For demo speed (In prod, use 50+)\n",
        "LR = 0.001\n",
        "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Load Item Count\n",
        "with open(\"/content/data/processed/meta.txt\", \"r\") as f:\n",
        "    ITEM_COUNT = int(f.read())\n",
        "\n",
        "print(f\"ðŸš€ Initializing SASRec on {DEVICE} for {ITEM_COUNT} items...\")\n",
        "\n",
        "# --- THE SASREC ARCHITECTURE ---\n",
        "class SASRec(nn.Module):\n",
        "    def __init__(self, item_num, hidden_units, max_len, num_heads, num_layers, dropout_rate):\n",
        "        super(SASRec, self).__init__()\n",
        "        self.item_emb = nn.Embedding(item_num + 1, hidden_units, padding_idx=0)\n",
        "        self.pos_emb = nn.Embedding(max_len, hidden_units)\n",
        "        self.emb_dropout = nn.Dropout(dropout_rate)\n",
        "\n",
        "        # Transformer Blocks\n",
        "        encoder_layer = nn.TransformerEncoderLayer(\n",
        "            d_model=hidden_units,\n",
        "            nhead=num_heads,\n",
        "            dropout=dropout_rate,\n",
        "            dim_feedforward=hidden_units * 4\n",
        "        )\n",
        "        self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)\n",
        "\n",
        "        self.last_layernorm = nn.LayerNorm(hidden_units)\n",
        "\n",
        "    def forward(self, log_seqs):\n",
        "        # Create Sequence Embeddings\n",
        "        seqs = self.item_emb(log_seqs)\n",
        "        positions = np.tile(np.array(range(log_seqs.shape[1])), [log_seqs.shape[0], 1])\n",
        "        seqs += self.pos_emb(torch.LongTensor(positions).to(DEVICE))\n",
        "\n",
        "        # Masking (Ignore Padding 0)\n",
        "        timeline_mask = (log_seqs == 0)\n",
        "\n",
        "        # Pass through Transformer\n",
        "        # PyTorch Transformer expects (Seq_Len, Batch, Hidden), so we transpose\n",
        "        seqs = seqs.transpose(0, 1)\n",
        "        output = self.transformer_encoder(seqs, src_key_padding_mask=timeline_mask)\n",
        "        output = output.transpose(0, 1)\n",
        "\n",
        "        output = self.last_layernorm(output)\n",
        "        return output # Returns vectors for all steps\n",
        "\n",
        "    def predict(self, log_seqs, item_indices):\n",
        "        # Used for Inference (Predict next item)\n",
        "        log_feats = self.forward(log_seqs)\n",
        "        final_feat = log_feats[:, -1, :] # Take the last step only\n",
        "        item_embs = self.item_emb(item_indices)\n",
        "        logits = (final_feat * item_embs).sum(dim=-1)\n",
        "        return logits\n",
        "\n",
        "# --- DATA LOADER ---\n",
        "class RecDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, max_len):\n",
        "        self.data = np.load(data_path, allow_pickle=True)\n",
        "        self.max_len = max_len\n",
        "\n",
        "    def __len__(self): return len(self.data)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        seq = self.data[idx]\n",
        "        # Pad sequence to fixed length (Left Padding is standard for RNN/Transf)\n",
        "        seq = seq[-self.max_len:]\n",
        "        padding_len = self.max_len - len(seq)\n",
        "        seq = [0] * padding_len + seq\n",
        "\n",
        "        target = seq[-1]      # The item we want to predict\n",
        "        input_seq = seq[:-1]  # The history\n",
        "        input_seq = [0] + input_seq # Shift padding back\n",
        "\n",
        "        return torch.tensor(input_seq, dtype=torch.long), torch.tensor(target, dtype=torch.long)\n",
        "\n",
        "# --- TRAINING LOOP ---\n",
        "def train():\n",
        "    train_dataset = RecDataset(\"/content/data/processed/train.npy\", MAX_LEN)\n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "\n",
        "    model = SASRec(ITEM_COUNT, HIDDEN_UNITS, MAX_LEN, NUM_HEADS, NUM_LAYERS, DROPOUT).to(DEVICE)\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=LR)\n",
        "    criterion = nn.CrossEntropyLoss(ignore_index=0) # Ignore padding 0\n",
        "\n",
        "    model.train()\n",
        "    for epoch in range(EPOCHS):\n",
        "        total_loss = 0\n",
        "        for step, (seqs, labels) in enumerate(train_loader):\n",
        "            seqs, labels = seqs.to(DEVICE), labels.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward Pass: Get vectors\n",
        "            log_feats = model(seqs)\n",
        "            final_feat = log_feats[:, -1, :] # Only predict based on the last step\n",
        "\n",
        "            # Calculate Scores against ALL items (Expensive but accurate)\n",
        "            # In production, we use Sampled Softmax, but for 3000 items, full softmax is fine\n",
        "            logits = torch.matmul(final_feat, model.item_emb.weight.transpose(0, 1))\n",
        "\n",
        "            loss = criterion(logits, labels)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            total_loss += loss.item()\n",
        "\n",
        "            if step % 100 == 0:\n",
        "                print(f\"Epoch {epoch+1} | Step {step} | Loss: {loss.item():.4f}\")\n",
        "\n",
        "    # Save Model Artifact\n",
        "    torch.save(model.state_dict(), \"sasrec_model.pth\")\n",
        "    print(\"ðŸ’¾ Model Saved: sasrec_model.pth\")\n",
        "    return model\n",
        "\n",
        "# Run Training\n",
        "trained_model = train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WNTv20iVnARb",
        "outputId": "2c19db0c-10ca-4081-8f33-0d5954f40fbf"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸš€ Initializing SASRec on cuda for 3707 items...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/nn/modules/transformer.py:392: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 | Step 0 | Loss: 36.0646\n",
            "Epoch 2 | Step 0 | Loss: 17.8119\n",
            "Epoch 3 | Step 0 | Loss: 14.3562\n",
            "Epoch 4 | Step 0 | Loss: 13.0311\n",
            "Epoch 5 | Step 0 | Loss: 11.4550\n",
            "Epoch 6 | Step 0 | Loss: 11.0445\n",
            "Epoch 7 | Step 0 | Loss: 9.3715\n",
            "Epoch 8 | Step 0 | Loss: 9.0682\n",
            "Epoch 9 | Step 0 | Loss: 9.0044\n",
            "Epoch 10 | Step 0 | Loss: 8.2011\n",
            "ðŸ’¾ Model Saved: sasrec_model.pth\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def recommend_next_items(model, history_seq, top_k=5):\n",
        "    model.eval()\n",
        "\n",
        "    # 1. Preprocess Input\n",
        "    # Pad to Max Len\n",
        "    seq = history_seq[-MAX_LEN:]\n",
        "    padding_len = MAX_LEN - len(seq)\n",
        "    seq = [0] * padding_len + seq\n",
        "\n",
        "    # Convert to Tensor\n",
        "    seq_tensor = torch.tensor([seq], dtype=torch.long).to(DEVICE)\n",
        "\n",
        "    # 2. Model Inference\n",
        "    with torch.no_grad():\n",
        "        # Get the embedding for the sequence\n",
        "        log_feats = model(seq_tensor)\n",
        "        final_feat = log_feats[:, -1, :] # The user's current \"state\"\n",
        "\n",
        "        # Calculate Scores (Dot Product with Item Embeddings)\n",
        "        item_embs = model.item_emb.weight\n",
        "        logits = torch.matmul(final_feat, item_embs.transpose(0, 1))\n",
        "\n",
        "        # Remove padding (0) and history items (don't recommend what they just watched)\n",
        "        logits[0, 0] = -float('inf')\n",
        "        for i in history_seq:\n",
        "            if i < ITEM_COUNT:\n",
        "                logits[0, i] = -float('inf')\n",
        "\n",
        "        # 3. Rank Top K\n",
        "        scores, indices = torch.topk(logits, top_k)\n",
        "\n",
        "    return indices[0].cpu().numpy().tolist()\n",
        "\n",
        "# --- LIVE TEST ---\n",
        "# Let's verify with a real movie sequence\n",
        "# IDs from MovieLens:\n",
        "# 1=Toy Story, 260=Star Wars IV, 1196=Star Wars V, 1210=Star Wars VI\n",
        "print(\"ðŸ§ª Testing Recommendation Engine...\")\n",
        "\n",
        "sci_fi_fan = [260, 1196, 1210] # Watched Original Star Wars Trilogy\n",
        "recs = recommend_next_items(trained_model, sci_fi_fan)\n",
        "\n",
        "print(f\"\\nUser Watched: {sci_fi_fan} (Star Wars Trilogy)\")\n",
        "print(f\"Recommended:  {recs}\")\n",
        "\n",
        "# 4. Decode (Optional: In a real app, we would map IDs back to Titles)\n",
        "# Since we don't have the titles loaded in RAM, we just trust the IDs for now.\n",
        "# Typically, 2628 (Star Wars I) or 1198 (Raiders of Lost Ark) should appear."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12a14FA2n7X6",
        "outputId": "7614dc85-5d49-447c-ddde-45f71d6e19e6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ðŸ§ª Testing Recommendation Engine...\n",
            "\n",
            "User Watched: [260, 1196, 1210] (Star Wars Trilogy)\n",
            "Recommended:  [186, 437, 887, 96, 272]\n"
          ]
        }
      ]
    }
  ]
}